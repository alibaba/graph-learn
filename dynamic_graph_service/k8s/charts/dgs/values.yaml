# Default values for Dynamic Graph Service.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# Dynamic Graph Service image version
# @param image.registry Dynamic Graph Service image registry
# @param image.repository Dynamic Graph Service image repository
# @param image.tag Dynamic Graph Service image tag (immutable tags are recommended)
# @param image.pullPolicy Dynamic Graph Service image pull policy
# @param image.pullSecrets Specify docker-registry secret names as an array
image:
  registry: "graphlearn"
  repository: "dgs-core"
  tag: "1.0.0"
  # Specify a imagePullPolicy
  # Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
  # ref: https://kubernetes.io/docs/user-guide/images/#pre-pulling-images
  #
  pullPolicy: IfNotPresent
  # Optionally specify an array of imagePullSecrets (secrets must be manually created in the namespace)
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  # Example:
  # pullSecrets:
  #   - myRegistryKeySecretName
  #
  pullSecrets: []

# @param nameOverride String to partially override dgs.fullname
#
nameOverride: ""

# @param fullnameOverride String to fully override dgs.fullname
#
fullnameOverride: ""

# @param clusterDomain Default Kubernetes cluster domain
#
clusterDomain: cluster.local

# @param commonLabels Labels to add to all deployed objects
#
commonLabels: {}

# @param commonAnnotations Annotations to add to all deployed objects
#
commonAnnotations: {}

# @param labelGroupOverride The self-managed label group prefix name to override dgs.label.group
# If set to null, `frontend.ingressHostName` will be used as the default label group name.
#
labelGroupOverride: ""

# Role Based Access
# ref: https://kubernetes.io/docs/admin/authorization/rbac/
#
rbac:
  # @param rbac.create Whether to create & use RBAC resources or not
  #
  create: false

# Service Account Access
# ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
#
serviceAccount:
  # Specifies whether a service account should be created
  # @param serviceAccount.create Enable creation of ServiceAccount for dgs pods
  #
  create: true
  # @param serviceAccount.name The name of the service account to use.
  # If not set and create is true, a name is generated using the dgs.serviceAccountName template
  #
  name: ""
  # Annotations to add to the service account
  # @param serviceAccount.annotations Additional custom annotations for the ServiceAccount
  #
  annotations: {}
  # @param serviceAccount.automountServiceAccountToken Allows auto mount of ServiceAccountToken on the serviceAccount created
  # Can be set to false if pods using this serviceAccount do not need to use K8s API
  #
  automountServiceAccountToken: true

# Google Logging Options
#
glog:
  # @param glog.toConsole whether program logs are written to standard error as well as to files.
  toConsole: false

# Kafka options
#
kafka:
  # Kafka topic info between dataloader and sampling workers
  #
  dl2spl:
    brokers:
      - "localhost:9092"
    topic: "record-batches"
    partitions: 4
  # Kafka topic info between sampling workers and serving workers
  #
  spl2srv:
    brokers:
      - "localhost:9092"
    topic: "sample-batches"
    partitions: 4

# @param configPath The dgs configmap mount path
#
configPath: "/dgs_conf"

# @param graphSchema The json string of graph schema
# Set it with option "--set-file graphSchema=/path/to/schema/json/file"
#
graphSchema: ""

# @param remoteFileRepoURL The url of remote file repository that contains service binary packages and datasets
#
remoteFileRepoURL: "https://graphlearn.oss-cn-hangzhou.aliyuncs.com"

# Front-End options
#
frontend:
  # @param frontend.ingressHostName The host name of external ingress
  #
  ingressHostName: "dynamic-graph-service.info"
  # @param frontend.limitConnections The number of concurrent connections allowed from a single IP address.
  # A 503 error is returned when exceeding this limit.
  #
  limitConnections: 1000

# Coordinator options
coordinator:
  # @param coordinator.updateStrategy.type coordinator deployment strategy type
  # @param coordinator.updateStrategy.rollingUpdate coordinator deployment rolling update configuration parameters
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  #
  updateStrategy:
    type: RollingUpdate
    rollingUpdate: {}
  # Extra coordinator pod labels
  # Ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  #
  podLabels: {}
  # Coordinator pod annotations
  # ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  #
  podAnnotations: {}
  # @param coordinator.podAffinityPreset Coordinator pod affinity preset. Ignored if `coordinator.affinity` is set. Allowed values: `soft` or `hard`
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  #
  podAffinityPreset: ""
  # @param coordinator.podAntiAffinityPreset Coordinator pod anti-affinity preset. Ignored if `coordinator.affinity` is set. Allowed values: `soft` or `hard`
  # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  #
  podAntiAffinityPreset: "soft"
  # Node coordinator.affinity preset
  # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  #
  nodeAffinityPreset:
    # @param coordinator.nodeAffinityPreset.type Node affinity preset type. Ignored if `coordinator.affinity` is set. Allowed values: `soft` or `hard`
    #
    type: ""
    # @param coordinator.nodeAffinityPreset.key Node label key to match Ignored if `coordinator.affinity` is set.
    # E.g.
    # key: "kubernetes.io/e2e-az-name"
    #
    key: ""
    # @param coordinator.nodeAffinityPreset.values Node label values to match. Ignored if `coordinator.affinity` is set.
    # E.g.
    # values:
    #   - e2e-az1
    #   - e2e-az2
    #
    values: []
  # @param coordinator.affinity Affinity for pod assignment
  # Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  # Note: coordinator.podAntiAffinityPreset, coordinator.podAntiAffinityPreset and coordinator.nodeAffinityPreset will be ignored when it's set
  #
  affinity: {}
  # Node labels for coordinator pods assignment
  # ref: https://kubernetes.io/docs/user-guide/node-selection/
  #
  nodeSelector: {}
  # Toleration for coordinator pods assignment
  # ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  #
  tolerations: []
  # Coordinator container's resource requests and limits
  # ref: http://kubernetes.io/docs/user-guide/compute-resources/
  #
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary.
  # resources:
  #   requests:
  #     cpu: "2"
  #     memory: "1Gi"
  #     ephemeral-storage: "10Gi"
  #   limits:
  #     cpu: "4"
  #     memory: "2Gi"
  #     ephemeral-storage: "20Gi"
  #
  resources: {}
  # Coordinator persistence options for checkpoints
  #
  persistence:
    # @param coordinator.persistence.enabled Enable coordinator checkpoints persistence using PVC
    # If set to false, the checkpoint files will be stored in an "emptyDir"
    #
    enabled: false
    # @param coordinator.persistence.existingClaim A manually managed Persistent Volume and Claim
    # If defined, PVC must be created manually before volume will be bound
    # The value is evaluated as a template
    #
    existingClaim: ""
    # @param coordinator.persistence.storageClass PVC Storage Class for checkpoints volume
    # If defined, storageClassName: <storageClass>
    # If set to "-", storageClassName: "", which disables dynamic provisioning
    # If undefined (the default) or set to null, no storageClassName spec is
    # set, choosing the default provisioner.
    #
    storageClass: "-"
    # @param coordinator.persistence.accessModes Persistent Volume Access Modes
    #
    accessModes:
      - ReadWriteOnce
    # @param coordinator.persistence.size PVC Storage Request for checkpoints volume
    #
    size: 20Gi
    # @param coordinator.persistence.annotations Annotations for the PVC
    #
    annotations: {}
    # @param coordinator.persistence.selector Selector to match an existing Persistent Volume for checkpoint data PVC.
    # If set, the PVC can't have a PV dynamically provisioned for it.
    # selector:
    #   matchLabels:
    #     app: my-app
    #
    selector: {}
    # @param coordinator.persistence.mountPath Mount path of the checkpoints volume
    #
    mountPath: "/coordinator_checkpoints"
  # Configure extra options for coordinator containers' liveness and readiness probes
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  # @param coordinator.livenessProbe.enabled Enable livenessProbe on coordinator containers
  # @param coordinator.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
  # @param coordinator.livenessProbe.periodSeconds Period seconds for livenessProbe
  # @param coordinator.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
  # @param coordinator.livenessProbe.failureThreshold Failure threshold for livenessProbe
  # @param coordinator.livenessProbe.successThreshold Success threshold for livenessProbe
  #
  livenessProbe:
    enabled: true
    initialDelaySeconds: 10
    periodSeconds: 10
    timeoutSeconds: 1
    failureThreshold: 3
    successThreshold: 1
  # @param coordinator.readinessProbe.enabled Enable readinessProbe on coordinator containers
  # @param coordinator.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
  # @param coordinator.readinessProbe.periodSeconds Period seconds for readinessProbe
  # @param coordinator.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
  # @param coordinator.readinessProbe.failureThreshold Failure threshold for readinessProbe
  # @param coordinator.readinessProbe.successThreshold Success threshold for readinessProbe
  #
  readinessProbe:
    enabled: true
    initialDelaySeconds: 5
    periodSeconds: 10
    timeoutSeconds: 1
    failureThreshold: 6
    successThreshold: 1
  # Coordinator Rpc Service (ClusterIP) parameters
  #
  rpcService:
    # @param coordinator.rpcService.port Coordinator rpc service port for internal connections
    #
    port: 50051
    # @param coordinator.rpcService.clusterIP Coordinator rpc service Cluster IP
    # e.g.:
    # clusterIP: None
    #
    clusterIP: ""
    # @param coordinator.rpcService.sessionAffinity Control where rpc requests go, to the same pod or round-robin
    # Values: ClientIP or None
    # ref: https://kubernetes.io/docs/user-guide/services/
    #
    sessionAffinity: None
    # @param coordinator.rpcService.annotations Additional custom annotations for coordinator rpc service
    #
    annotations: {}
  # Coordinator Http Service (NodePort) parameters
  #
  httpService:
    # @param coordinator.httpService.ports Coordinator http service port for external admin requests
    #
    port: 8080
    # @param coordinator.httpService.sessionAffinity Control where http requests go, to the same pod or round-robin
    # Values: ClientIP or None
    # ref: https://kubernetes.io/docs/user-guide/services/
    #
    sessionAffinity: None
    # @param coordinator.httpService.externalTrafficPolicy Coordinator http service external traffic policy
    # ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    #
    externalTrafficPolicy: Cluster
    # @param coordinator.httpService.annotations Additional custom annotations for coordinator http service
    #
    annotations: {}
  # @param coordinator.workdir Local ephemeral storage mount path for Coordinator working directory
  #
  workdir: "/coordinator_workdir"
  # @param coordinator.connectTimeoutSeconds The max timeout seconds when other workers connect to coordinator
  #
  connectTimeoutSeconds: 60
  # @param coordinator.heartbeatIntervalSeconds The heartbeat interval in seconds when other workers report statistics to coordinator
  #
  heartbeatIntervalSeconds: 10


# Sampling Worker options
#
sampling:
  # @param sampling.workerNum Number of Sampling Workers
  #
  workerNum: 2
  # @param sampling.updateStrategy.type Sampling worker deployment strategy type
  # @param sampling.updateStrategy.rollingUpdate Sampling worker deployment rolling update configuration parameters
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  #
  updateStrategy:
    type: RollingUpdate
    rollingUpdate: {}
  # Extra sampling worker pod labels
  # Ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  #
  podLabels: {}
  # Sampling worker pod annotations
  # ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  #
  podAnnotations: {}
  # @param sampling.podAffinityPreset Sampling worker pod affinity preset. Ignored if `sampling.affinity` is set. Allowed values: `soft` or `hard`
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  #
  podAffinityPreset: ""
  # @param sampling.podAntiAffinityPreset Sampling worker pod anti-affinity preset. Ignored if `sampling.affinity` is set. Allowed values: `soft` or `hard`
  # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  #
  podAntiAffinityPreset: "soft"
  # Node sampling.affinity preset
  # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  #
  nodeAffinityPreset:
    # @param sampling.nodeAffinityPreset.type Node affinity preset type. Ignored if `sampling.affinity` is set. Allowed values: `soft` or `hard`
    #
    type: ""
    # @param sampling.nodeAffinityPreset.key Node label key to match Ignored if `sampling.affinity` is set.
    # E.g.
    # key: "kubernetes.io/e2e-az-name"
    #
    key: ""
    # @param sampling.nodeAffinityPreset.values Node label values to match. Ignored if `sampling.affinity` is set.
    # E.g.
    # values:
    #   - e2e-az1
    #   - e2e-az2
    #
    values: []
  # @param sampling.affinity Affinity for pod assignment
  # Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  # Note: sampling.podAntiAffinityPreset, sampling.podAntiAffinityPreset and sampling.nodeAffinityPreset will be ignored when it's set
  #
  affinity: {}
  # Node labels for sampling worker pods assignment
  # ref: https://kubernetes.io/docs/user-guide/node-selection/
  #
  nodeSelector: {}
  # Toleration for sampling worker pods assignment
  # ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  #
  tolerations: []
  # Sampling worker container's resource requests and limits
  # ref: http://kubernetes.io/docs/user-guide/compute-resources/
  #
  resources: {}
  # Sampling worker persistence options for checkpoints
  #
  persistence:
    # @param sampling.persistence.enabled Enable sampling worker checkpoints persistence using PVC
    # If set to false, the checkpoint files will be stored in an "emptyDir"
    #
    enabled: false
    # @param sampling.persistence.existingClaim A manually managed Persistent Volume and Claim
    # If defined, PVC must be created manually before volume will be bound
    # The value is evaluated as a template
    #
    existingClaim: ""
    # @param sampling.persistence.storageClass PVC Storage Class for checkpoints volume
    # If defined, storageClassName: <storageClass>
    # If set to "-", storageClassName: "", which disables dynamic provisioning
    # If undefined (the default) or set to null, no storageClassName spec is
    # set, choosing the default provisioner.
    #
    storageClass: ""
    # @param sampling.persistence.accessModes Persistent Volume Access Modes
    #
    accessModes:
      - ReadWriteOnce
    # @param sampling.persistence.size PVC Storage Request for checkpoints volume
    #
    size: 20Gi
    # @param sampling.persistence.annotations Annotations for the PVC
    #
    annotations: {}
    # @param sampling.persistence.selector Selector to match an existing Persistent Volume for checkpoint data PVC.
    # If set, the PVC can't have a PV dynamically provisioned for it.
    # selector:
    #   matchLabels:
    #     app: my-app
    #
    selector: {}
    # @param sampling.persistence.mountPath Mount path of the checkpoints volume
    #
    mountPath: "/sampling_checkpoints"
  # Configure extra options for sampling worker containers' liveness probe
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  # @param sampling.livenessProbe.enabled Enable livenessProbe on sampling worker containers
  # @param sampling.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
  # @param sampling.livenessProbe.periodSeconds Period seconds for livenessProbe
  # @param sampling.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
  # @param sampling.livenessProbe.failureThreshold Failure threshold for livenessProbe
  # @param sampling.livenessProbe.successThreshold Success threshold for livenessProbe
  #
  livenessProbe:
    enabled: true
    initialDelaySeconds: 10
    periodSeconds: 10
    timeoutSeconds: 1
    failureThreshold: 3
    successThreshold: 1
  # @param sampling.workdir Local ephemeral storage mount path for Sampling Worker working directory
  #
  workdir: "/sampling_workdir"
  # @param sampling.actorLocalShardNum Local computing shard number for each Sampling Worker pod
  #
  actorLocalShardNum: 4
  # @param sampling.dataPartitionNum The total partition number of data across all Sampling Workers
  #
  # Note: Each Sampling Worker only manages a part of data partitions
  # E.g. Assuming "sampling.dataPartitionNum = 8" and "sampling.workerNum = 2", then:
  #   Sampling Worker 0 manages data partition 0, 2, 4, 6
  #   Sampling Worker 1 manages data partition 1, 3, 5, 7
  #
  dataPartitionNum: 8
  # Rocksdb environment options
  # @param sampling.rocksdbEnv.highPriorityThreads The thread num of high-priority rocksdb background tasks
  # @param sampling.rocksdbEnv.lowPriorityThreads The thread num of low-priority rocksdb background tasks
  #
  rocksdbEnv:
    highPriorityThreads: 2
    lowPriorityThreads: 2
  # Sample Store Options
  # @param sampling.sampleStore.memtableRep The rocksdb memtable structure type of sample store
  # @param sampling.sampleStore.hashBucketCount The hash bucket count of sample store memtable
  # @param sampling.sampleStore.skipListLookahead The look-ahead factor of sample store memtable
  # @param sampling.sampleStore.blockCacheCapacity The capacity (bytes) of sample store block cache
  # @param sampling.sampleStore.ttlHours The TTL hours for sampling data in sample store
  #
  sampleStore:
    memtableRep: "hashskiplist"
    hashBucketCount: 1048576
    skipListLookahead: 0
    blockCacheCapacity: 67108864
    ttlHours: 1200
  # Subscription Table Options
  # @param sampling.subscriptionTable.memtableRep The rocksdb memtable structure type of Sampling subscription table
  # @param sampling.subscriptionTable.hashBucketCount The hash bucket count of subscription table memtable
  # @param sampling.subscriptionTable.skipListLookahead The look-ahead factor of subscription table memtable
  # @param sampling.subscriptionTable.blockCacheCapacity The capacity (bytes) of subscription table block cache
  # @param sampling.subscriptionTable.ttlHours The TTL hours for sampling rules in subscription table
  #
  subscriptionTable:
    memtableRep: "hashskiplist"
    hashBucketCount: 1048576
    skipListLookahead: 0
    blockCacheCapacity: 67108864
    ttlHours: 1200
  # Record Polling Options
  # @param sampling.recordPolling.threadNum The thread number for graph update consuming from kafka queues
  # @param sampling.recordPolling.retryIntervalMs The retry interval (ms) when no record has been polled
  # @param sampling.recordPolling.processConcurrency The max processing concurrency for polled records
  #
  recordPolling:
    threadNum: 2
    retryIntervalMs: 100
    processConcurrency: 100
  # Sample Publishing Options
  # @param sampling.samplePublishing.producerPoolSize The max number of kafka producer for sampling results
  # @param sampling.samplePublishing.maxProduceRetryTimes The maximum retry times of producing a kafka message
  # @param sampling.samplePublishing.callbackPollIntervalMs The interval (ms) for polling async producing callbacks
  #
  samplePublishing:
    producerPoolSize: 2
    maxProduceRetryTimes: 3
    callbackPollIntervalMs: 100
  # Logging Options
  # @param sampling.logging.dataLogPeriod Specify how many graph update batches should be processed between two logs produced
  # @param sampling.logging.ruleLogPeriod Specify how many sampling rules should be processed between two logs produced
  #
  logging:
    dataLogPeriod: 10
    ruleLogPeriod: 10


# Serving Worker options
#
serving:
  # @param serving.workerNum Number of Serving Workers
  # each Serving Worker is an independent pod
  #
  workerNum: 2
  # @param serving.updateStrategy.type Serving worker deployment strategy type
  # @param serving.updateStrategy.rollingUpdate Serving worker deployment rolling update configuration parameters
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  #
  updateStrategy:
    type: RollingUpdate
    rollingUpdate: {}
  # Extra serving worker pod labels
  # Ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  #
  podLabels: {}
  # Serving worker pod annotations
  # ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  #
  podAnnotations: {}
  # @param serving.podAffinityPreset Serving worker pod affinity preset. Ignored if `serving.affinity` is set. Allowed values: `soft` or `hard`
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  #
  podAffinityPreset: ""
  # @param serving.podAntiAffinityPreset Serving worker pod anti-affinity preset. Ignored if `serving.affinity` is set. Allowed values: `soft` or `hard`
  # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  #
  podAntiAffinityPreset: "soft"
  # Node serving.affinity preset
  # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  #
  nodeAffinityPreset:
    # @param serving.nodeAffinityPreset.type Node affinity preset type. Ignored if `serving.affinity` is set. Allowed values: `soft` or `hard`
    #
    type: ""
    # @param serving.nodeAffinityPreset.key Node label key to match Ignored if `serving.affinity` is set.
    # E.g.
    # key: "kubernetes.io/e2e-az-name"
    #
    key: ""
    # @param serving.nodeAffinityPreset.values Node label values to match. Ignored if `serving.affinity` is set.
    # E.g.
    # values:
    #   - e2e-az1
    #   - e2e-az2
    #
    values: []
  # @param serving.affinity Affinity for pod assignment
  # Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  # Note: serving.podAntiAffinityPreset, serving.podAntiAffinityPreset and serving.nodeAffinityPreset will be ignored when it's set
  #
  affinity: {}
  # Node labels for serving worker pods assignment
  # ref: https://kubernetes.io/docs/user-guide/node-selection/
  #
  nodeSelector: {}
  # Toleration for serving worker pods assignment
  # ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  #
  tolerations: []
  # Serving worker container's resource requests and limits
  # ref: http://kubernetes.io/docs/user-guide/compute-resources/
  #
  resources: {}
  # Serving worker persistence options for checkpoints
  #
  persistence:
    # @param serving.persistence.enabled Enable serving worker checkpoints persistence using PVC
    # If set to false, the checkpoint files will be stored in an "emptyDir"
    #
    enabled: false
    # @param serving.persistence.existingClaim A manually managed Persistent Volume and Claim
    # If defined, PVC must be created manually before volume will be bound
    # The value is evaluated as a template
    #
    existingClaim: ""
    # @param serving.persistence.storageClass PVC Storage Class for checkpoints volume
    # If defined, storageClassName: <storageClass>
    # If set to "-", storageClassName: "", which disables dynamic provisioning
    # If undefined (the default) or set to null, no storageClassName spec is
    # set, choosing the default provisioner.
    #
    storageClass: ""
    # @param serving.persistence.accessModes Persistent Volume Access Modes
    #
    accessModes:
      - ReadWriteOnce
    # @param serving.persistence.size PVC Storage Request for checkpoints volume
    #
    size: 20Gi
    # @param serving.persistence.annotations Annotations for the PVC
    #
    annotations: {}
    # @param serving.persistence.selector Selector to match an existing Persistent Volume for checkpoint data PVC.
    # If set, the PVC can't have a PV dynamically provisioned for it.
    # selector:
    #   matchLabels:
    #     app: my-app
    #
    selector: {}
    # @param serving.persistence.mountPath Mount path of the checkpoints volume
    #
    mountPath: "/serving_checkpoints"
  # Configure extra options for serving worker containers' liveness and readiness probes
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  # @param serving.livenessProbe.enabled Enable livenessProbe on coordinator containers
  # @param serving.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
  # @param serving.livenessProbe.periodSeconds Period seconds for livenessProbe
  # @param serving.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
  # @param serving.livenessProbe.failureThreshold Failure threshold for livenessProbe
  # @param serving.livenessProbe.successThreshold Success threshold for livenessProbe
  #
  livenessProbe:
    enabled: true
    initialDelaySeconds: 10
    periodSeconds: 10
    timeoutSeconds: 1
    failureThreshold: 3
    successThreshold: 1
  # @param serving.readinessProbe.enabled Enable readinessProbe on coordinator containers
  # @param serving.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
  # @param serving.readinessProbe.periodSeconds Period seconds for readinessProbe
  # @param serving.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
  # @param serving.readinessProbe.failureThreshold Failure threshold for readinessProbe
  # @param serving.readinessProbe.successThreshold Success threshold for readinessProbe
  #
  readinessProbe:
    enabled: true
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 1
    failureThreshold: 6
    successThreshold: 1
  # Serving Worker Http Service (NodePort) parameters
  #
  httpService:
    # @param serving.httpService.ports The external port of Serving http service for inference queries
    #
    port: 10000
    # @param serving.httpService.sessionAffinity Control where http requests go, to the same pod or round-robin
    # Values: ClientIP or None
    # ref: https://kubernetes.io/docs/user-guide/services/
    #
    sessionAffinity: None
    # @param serving.httpService.externalTrafficPolicy The external traffic policy of Serving http service
    # ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    #
    externalTrafficPolicy: Cluster
    # @param serving.httpService.annotations Additional custom annotations of Serving http service
    #
    annotations: {}
  # @param serving.workdir Local ephemeral storage mount path for Serving Worker working directory
  #
  workdir: "/serving_workdir"
  # @param serving.actorLocalShardNum Local computing shard number for each Serving Worker pod
  #
  actorLocalShardNum: 4
  # @param serving.dataPartitionNum The partition number of data for each Serving Worker
  #
  # Note: Each Serving Worker manages all data partitions standalone
  # E.g. Assuming "serving.dataPartitionNum = 4" and "serving.workerNum = 2", then:
  #   Serving Worker 0 manages all data partitions 0, 1, 2, 3
  #   Serving Worker 1 manages all data partitions 0, 1, 2, 3
  #
  dataPartitionNum: 4
  # Rocksdb environment options
  # @param serving.rocksdbEnv.highPriorityThreads The thread num of high-priority rocksdb background tasks
  # @param serving.rocksdbEnv.lowPriorityThreads The thread num of low-priority rocksdb background tasks
  #
  rocksdbEnv:
    highPriorityThreads: 2
    lowPriorityThreads: 2
  # Sample Store Options
  # Note: The sample store of Serving Worker is managed and partitioned by worker itself
  #
  # @param serving.sampleStore.inMemoryMode Specify whether to open rocksdb in-memory mode of sample store
  # @param serving.sampleStore.memtableRep The rocksdb memtable structure type of sample store
  # @param serving.sampleStore.hashBucketCount The hash bucket count of sample store memtable
  # @param serving.sampleStore.skipListLookahead The look-ahead factor of sample store memtable
  # @param serving.sampleStore.blockCacheCapacity The capacity(bytes) of sample store block cache
  # @param serving.sampleStore.ttlHours The TTL hours for serving data in sample store
  #
  sampleStore:
    inMemoryMode: false
    memtableRep: "hashskiplist"
    hashBucketCount: 1048576
    skipListLookahead: 0
    blockCacheCapacity: 67108864
    ttlHours: 1200
  # Record Polling Options
  # @param serving.recordPolling.threadNum The thread number for sample update consuming from kafka queues
  # @param serving.recordPolling.retryIntervalMs The retry interval (ms) when no record has been polled
  # @param serving.recordPolling.processConcurrency The max processing concurrency for polled records
  #
  recordPolling:
    threadNum: 2
    retryIntervalMs: 100
    processConcurrency: 100
  # Logging Options
  # @param serving.logging.dataLogPeriod Specify how many sample update batches should be processed between two logs produced
  # @param serving.logging.requestLogPeriod Interval of incoming inference query requests for logging serving statistics
  #
  logging:
    dataLogPeriod: 10
    requestLogPeriod: 1
